import streamlit as st
import pandas as pd
import os
import tempfile
import time
from backend import DormDataProcessor
import numpy as np
from typing import List, Dict, Tuple
import logging
import sys
import subprocess
import webbrowser

# å°è¯•å¯¼å…¥dotenvï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æä¾›æç¤ºä½†ä¸ç»ˆæ­¢ç¨‹åº
try:
    from dotenv import load_dotenv
    dotenv_available = True
except ImportError:
    dotenv_available = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ä»run.pyåˆå¹¶çš„åŠŸèƒ½ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡
def check_env():
    """æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦å·²é…ç½®"""
    if not dotenv_available:
        st.warning("âš ï¸ ç¼ºå°‘ python-dotenv ä¾èµ–ï¼šç¯å¢ƒå˜é‡æ— æ³•æ­£ç¡®åŠ è½½")
        st.info("æ‚¨å¯ä»¥è¿è¡Œ `pip install python-dotenv` å®‰è£…æ­¤ä¾èµ–")
        # å°è¯•ç›´æ¥ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        if not os.getenv("DEEPSEEK_API_KEY"):
            st.warning("âš ï¸ æœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼è¯·è®¾ç½®æ­¤ç¯å¢ƒå˜é‡ã€‚")
            st.info("æ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ª.envæ–‡ä»¶ï¼Œå¹¶æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\nDEEPSEEK_API_KEY=æ‚¨çš„APIå¯†é’¥")
            return False
        return True
    
    # å¦‚æœdotenvå¯ç”¨ï¼ŒåŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    if not os.getenv("DEEPSEEK_API_KEY"):
        st.warning("âš ï¸ æœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ã€‚")
        st.info("æ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ª.envæ–‡ä»¶ï¼Œå¹¶æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\nDEEPSEEK_API_KEY=æ‚¨çš„APIå¯†é’¥")
        return False
    return True

# ä»run.pyåˆå¹¶çš„åŠŸèƒ½ï¼šæ£€æŸ¥ä¾èµ–
def check_dependencies():
    """æ£€æŸ¥æ‰€éœ€ä¾èµ–æ˜¯å¦å·²å®‰è£…ï¼ˆStreamlitç‰ˆæœ¬ï¼‰"""
    required = ["streamlit", "pandas", "openpyxl", "requests"]
    
    missing = []
    for package in required:
        try:
            __import__(package)
        except ImportError:
            missing.append(package)
    
    # å•ç‹¬æ£€æŸ¥python-dotenvï¼Œå› ä¸ºå‰é¢å·²ç»å¤„ç†è¿‡è¿™ä¸ªä¾èµ–
    if not dotenv_available:
        missing.append("python-dotenv")
    
    if missing:
        st.error(f"âš ï¸ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–: {', '.join(missing)}")
        st.info(f"è¯·å®‰è£…æ‰€éœ€ä¾èµ–: pip install {' '.join(missing)}")
        return False
    return True

# ä»run.pyåˆå¹¶çš„åŠŸèƒ½ï¼šæ¼”ç¤ºè·å–æ¨¡å‹åˆ—è¡¨
def demo_list_models():
    """æ¼”ç¤ºè·å–æ¨¡å‹åˆ—è¡¨çš„ä»£ç ï¼ˆStreamlitç‰ˆæœ¬ï¼‰"""
    if not dotenv_available:
        st.error("âš ï¸ ç¼ºå°‘ python-dotenv ä¾èµ–ï¼Œæ— æ³•æ‰§è¡Œç¤ºä¾‹ã€‚")
        st.info("è¯·è¿è¡Œ `pip install python-dotenv` å®‰è£…æ­¤ä¾èµ–")
        return
        
    st.subheader("DeepSeekæ¨¡å‹åˆ—è¡¨ç¤ºä¾‹")
    
    st.code("""from openai import OpenAI

# åˆ›å»ºå®¢æˆ·ç«¯
client = OpenAI(api_key="<æ‚¨çš„APIå¯†é’¥>", base_url="https://api.deepseek.com")

# è·å–æ¨¡å‹åˆ—è¡¨
models = client.models.list()

# æ‰“å°æ¨¡å‹ä¿¡æ¯
print("å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
for model in models.data:
    print(f"- {model.id}")""", language="python")
    
    if st.button("æ‰§è¡Œç¤ºä¾‹ä»£ç "):
        try:
            from openai import OpenAI
            
            # è·å–APIå¯†é’¥
            api_key = os.getenv("DEEPSEEK_API_KEY")
            if not api_key:
                st.warning("âš ï¸ æœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼")
                return
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
            
            # è·å–æ¨¡å‹åˆ—è¡¨
            try:
                models = client.models.list()
                
                # æ‰“å°æ¨¡å‹ä¿¡æ¯
                st.success("è·å–æ¨¡å‹åˆ—è¡¨æˆåŠŸ!")
                st.write("å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
                for model in models.data:
                    st.write(f"- {model.id}")
            except Exception as e:
                st.error(f"âš ï¸ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
                st.info("è¯·ç¡®ä¿æ‚¨çš„APIå¯†é’¥æ­£ç¡®ï¼Œå¹¶ä¸”ç½‘ç»œè¿æ¥æ­£å¸¸ã€‚")
        except ImportError:
            st.error("âš ï¸ æœªå®‰è£…æ‰€éœ€ä¾èµ–ï¼Œæ— æ³•æ‰§è¡Œç¤ºä¾‹ã€‚")
            st.info("è¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–: openai, python-dotenv")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŠå²›æ™ºå®¿ç³»ç»Ÿ",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main {
        background-color: #f5f7f9;
    }
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .step-container {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    .info-box {
        background-color: #e0f7fa;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .warning-box {
        background-color: #fff3e0;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .success-box {
        background-color: #e8f5e9;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    h1, h2, h3 {
        color: #0e4a67;
    }
    .stButton>button {
        background-color: #0e4a67;
        color: white;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #1976d2;
    }
    /* è‡ªå®šä¹‰èŠå¤©å®¹å™¨ */
    .chat-container {
        height: 400px;
        overflow-y: auto;
        padding: 10px;
        border-radius: 10px;
        background-color: #f9f9f9;
        margin-bottom: 10px;
        border: 1px solid #ddd;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'original_df' not in st.session_state:
    st.session_state.original_df = None
if 'processed_df' not in st.session_state:
    st.session_state.processed_df = None
if 'processing_msg' not in st.session_state:
    st.session_state.processing_msg = ""
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = ""
if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []
if 'processed_chat_messages' not in st.session_state:
    st.session_state.processed_chat_messages = []
if 'table_json' not in st.session_state:
    st.session_state.table_json = None
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "deepseek-chat"
if 'uploaded_files_info' not in st.session_state:
    st.session_state.uploaded_files_info = []  # å­˜å‚¨å·²ä¸Šä¼ æ–‡ä»¶çš„ä¿¡æ¯
if 'all_dataframes' not in st.session_state:
    st.session_state.all_dataframes = []  # å­˜å‚¨æ‰€æœ‰ä¸Šä¼ çš„æ•°æ®æ¡†ï¼ŒåŒ…æ‹¬åˆ—ä¸åŒ¹é…çš„

# åˆå§‹åŒ–å®¿èˆæ•°æ®å¤„ç†å™¨
processor = DormDataProcessor()

# åº”ç”¨æ ‡é¢˜
st.title("åŠå²›æ™ºå®¿ç³»ç»Ÿ")
st.markdown("---")

# å¤„ç†é‡å¤åˆ—å‡½æ•°
def clean_dataframe(df):
    if df is None:
        return None
    
    # æŸ¥æ‰¾å½¢å¦‚"X.1"çš„é‡å¤åˆ—å
    duplicate_cols = []
    for col in df.columns:
        if '.' in col and col.split('.')[-1].isdigit():
            base_col = col.split('.')[0]
            if base_col in df.columns:
                duplicate_cols.append(col)
    
    # åˆ é™¤é‡å¤åˆ—
    if duplicate_cols:
        df = df.drop(columns=duplicate_cols)
    
    return df

# æ ¼å¼åŒ–DataFrameä¸ºæ¸…æ™°çš„è¡¨æ ¼å½¢å¼
def format_dataframe(df, max_rows=10):
    """å°†DataFrameæ ¼å¼åŒ–ä¸ºæ¸…æ™°æ˜“è¯»çš„è¡¨æ ¼å½¢å¼"""
    if len(df) == 0:
        return "ç©ºæ•°æ®è¡¨"
    
    # é™åˆ¶è¡Œæ•°
    display_df = df.head(max_rows)
    
    # è·å–åˆ—å
    headers = list(display_df.columns)
    
    # æ ¼å¼åŒ–è¡¨å¤´
    header_row = "| " + " | ".join(headers) + " |"
    separator = "| " + " | ".join(["-" * len(col) for col in headers]) + " |"
    
    # æ ¼å¼åŒ–æ•°æ®è¡Œ
    data_rows = []
    for _, row in display_df.iterrows():
        formatted_row = "| " + " | ".join([str(row[col]) for col in headers]) + " |"
        data_rows.append(formatted_row)
    
    # ç»„åˆæˆè¡¨æ ¼
    table = [header_row, separator] + data_rows
    
    # æ·»åŠ è¡Œæ•°ä¿¡æ¯
    rows_info = f"\n\næ€»è¡Œæ•°: {len(df)} è¡Œï¼Œæ˜¾ç¤ºå‰ {min(max_rows, len(df))} è¡Œ"
    
    return "\n".join(table) + rows_info

# ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ Excelæ–‡ä»¶
with st.container():
    st.markdown('<div class="step-container">', unsafe_allow_html=True)
    st.subheader("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ Excelæ–‡ä»¶")
    
    # ä¿®æ”¹ä¸ºæ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼Œæœ€å¤š5ä¸ªæ–‡ä»¶
    uploaded_files = st.file_uploader("é€‰æ‹©å®¿èˆæ•°æ®Excelæ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼Œæœ€å¤š5ä¸ªï¼‰", type=["xlsx", "xls"], accept_multiple_files=True)
    
    # é™åˆ¶æ–‡ä»¶æ•°é‡
    if len(uploaded_files) > 5:
        st.warning("âš ï¸ æœ€å¤šåªèƒ½ä¸Šä¼ 5ä¸ªæ–‡ä»¶ï¼Œå°†åªå¤„ç†å‰5ä¸ªæ–‡ä»¶")
        uploaded_files = uploaded_files[:5]
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if uploaded_files and st.button("è¯»å–æ–‡ä»¶å†…å®¹"):
            with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶..."):
                # åˆå¹¶åçš„æ•°æ®æ¡†
                combined_df = None
                
                # æ¸…é™¤ä¹‹å‰çš„ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯å’Œæ•°æ®æ¡†
                st.session_state.uploaded_files_info = []
                st.session_state.all_dataframes = []
                
                # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
                for uploaded_file in uploaded_files:
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                        tmp.write(uploaded_file.getvalue())
                        temp_path = tmp.name
                    
                    try:
                        # è¯»å–åŸå§‹æ–‡ä»¶ï¼Œä½†ä¸è®¡ç®—è´¹ç”¨
                        file_df = processor.process_excel(temp_path, calculate=False)
                        
                        # æ¸…ç†é‡å¤åˆ—
                        file_df = clean_dataframe(file_df)
                        
                        # è®°å½•æ–‡ä»¶ä¿¡æ¯
                        file_info = {
                            "filename": uploaded_file.name,
                            "rows": len(file_df),
                            "columns": list(file_df.columns)
                        }
                        st.session_state.uploaded_files_info.append(file_info)
                        
                        # ä¿å­˜æ¯ä¸ªæ–‡ä»¶çš„æ•°æ®æ¡† - æ–°å¢çš„åŠŸèƒ½
                        st.session_state.all_dataframes.append({
                            "filename": uploaded_file.name,
                            "dataframe": file_df
                        })
                        
                        # å°†æ•°æ®åˆå¹¶åˆ°ä¸»æ•°æ®æ¡†
                        if combined_df is None:
                            combined_df = file_df
                        else:
                            # å°è¯•åˆå¹¶æ•°æ®æ¡†ï¼Œå¤„ç†å¯èƒ½çš„åˆ—ä¸åŒ¹é…é—®é¢˜
                            try:
                                # æ£€æŸ¥åˆ—åæ˜¯å¦ä¸€è‡´
                                if set(combined_df.columns) == set(file_df.columns):
                                    # åˆ—åå®Œå…¨ä¸€è‡´ï¼Œç›´æ¥åˆå¹¶
                                    combined_df = pd.concat([combined_df, file_df], ignore_index=True)
                                else:
                                    # åˆ—åä¸å®Œå…¨ä¸€è‡´ï¼Œåªåˆå¹¶å…±åŒçš„åˆ—
                                    common_cols = list(set(combined_df.columns) & set(file_df.columns))
                                    if common_cols:
                                        # è‡³å°‘æœ‰ä¸€äº›å…±åŒåˆ—ï¼Œåˆå¹¶è¿™äº›åˆ—
                                        combined_df = pd.concat(
                                            [combined_df[common_cols], file_df[common_cols]], 
                                            ignore_index=True
                                        )
                                        st.info(f"â„¹ï¸ æ–‡ä»¶ '{uploaded_file.name}' çš„åˆ—ä¸å…¶ä»–æ–‡ä»¶ä¸å®Œå…¨åŒ¹é…ï¼Œåªåˆå¹¶äº†å…±åŒçš„åˆ—ï¼Œä½†æ–‡ä»¶å·²å®Œæ•´è¯»å–")
                                    else:
                                        # æ²¡æœ‰å…±åŒåˆ—ï¼Œä½†ä»ä¿å­˜æ–‡ä»¶æ•°æ®
                                        st.info(f"â„¹ï¸ æ–‡ä»¶ '{uploaded_file.name}' çš„åˆ—ä¸å…¶ä»–æ–‡ä»¶å®Œå…¨ä¸åŒ¹é…ï¼Œä¸ä¼šåˆå¹¶åˆ°ä¸»æ•°æ®è¡¨ï¼Œä½†æ–‡ä»¶å·²å®Œæ•´è¯»å–")
                            except Exception as merge_err:
                                st.warning(f"åˆå¹¶æ–‡ä»¶ '{uploaded_file.name}' æ—¶å‡ºé”™: {str(merge_err)}ï¼Œä½†æ–‡ä»¶å·²å®Œæ•´è¯»å–")
                        
                    except Exception as e:
                        st.error(f"è¯»å–æ–‡ä»¶ '{uploaded_file.name}' æ—¶å‡ºé”™: {str(e)}")
                    
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    os.unlink(temp_path)
                
                if combined_df is not None:
                    # æ›´æ–°ä¼šè¯çŠ¶æ€
                    st.session_state.original_df = combined_df
                    st.session_state.processed_df = None  # æ¸…é™¤ä¹‹å‰çš„å¤„ç†ç»“æœ
                    st.session_state.processing_msg = ""
                    st.session_state.analysis_result = ""
                    
                    # æ¸…ç©ºä¹‹å‰çš„èŠå¤©è®°å½•
                    st.session_state.chat_messages = []
                    st.session_state.processed_chat_messages = []
                    
                    # æ„å»ºæ–‡ä»¶ä¿¡æ¯æ‘˜è¦
                    files_summary = ""
                    for i, file_info in enumerate(st.session_state.uploaded_files_info):
                        files_summary += f"ğŸ“„ {i+1}. {file_info['filename']}: {file_info['rows']}è¡Œæ•°æ®ï¼Œ{len(file_info['columns'])}åˆ—\n"
                    
                    # æ„å»ºåˆå§‹ç³»ç»Ÿæ¶ˆæ¯
                    initial_message = f"""æ‚¨å¥½ï¼æˆ‘å·²æˆåŠŸè¯»å–æ‚¨ä¸Šä¼ çš„{len(st.session_state.uploaded_files_info)}ä¸ªæ–‡ä»¶ã€‚

å·²å¤„ç†çš„æ–‡ä»¶ï¼š
{files_summary}

ä¸»æ•°æ®è¡¨åŒ…å«{len(combined_df)}æ¡è®°å½•ã€‚
æ‚¨å¯ä»¥å‘æˆ‘è¯¢é—®å…³äºä»»ä½•å·²ä¸Šä¼ æ–‡ä»¶çš„é—®é¢˜ã€‚"""

                    st.session_state.chat_messages.append({
                        "role": "assistant", 
                        "content": initial_message
                    })
                    
                    # æä¾›æ‰€æœ‰æ•°æ®æ¡†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
                    all_dfs_context = ""
                    for i, df_info in enumerate(st.session_state.all_dataframes):
                        filename = df_info["filename"]
                        df = df_info["dataframe"]
                        # æœ€å¤š15è¡Œæ ·æœ¬
                        sample_rows = min(10, len(df))
                        df_sample = format_dataframe(df, sample_rows)
                        all_dfs_context += f"\næ–‡ä»¶ {i+1}: {filename}\n{df_sample}\n\n"
                    
                    # æä¾›ä¸»æ•°æ®æ¡†çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
                    try:
                        df_info = pd.DataFrame({
                            'ç»Ÿè®¡é‡': combined_df.describe().index,
                            **{col: combined_df[col].describe() for col in combined_df.select_dtypes(include=np.number).columns[:5]}  # é™åˆ¶ä¸ºå‰5ä¸ªæ•°å€¼åˆ—
                        })
                        df_info_formatted = format_dataframe(df_info)

                        # è·å–å®é™…æ•°æ®æ ·æœ¬ï¼Œä¸ä»…ä»…æ˜¯ç»Ÿè®¡æ‘˜è¦
                        sample_rows = min(15, len(combined_df))  # æœ€å¤š15è¡Œæ ·æœ¬
                        df_sample_formatted = format_dataframe(combined_df, sample_rows)

                        # è·å–åˆ—åè¯¦ç»†åˆ—è¡¨
                        column_info = []
                        for col in combined_df.columns:
                            dtype = str(combined_df[col].dtype)
                            unique_values = combined_df[col].nunique()
                            sample_val = str(combined_df[col].iloc[0])
                            if len(sample_val) > 30:  # å¦‚æœæ ·æœ¬å€¼å¤ªé•¿ï¼Œæˆªæ–­å®ƒ
                                sample_val = sample_val[:30] + "..."
                            column_info.append(f"- {col}: {dtype} (æ ·æœ¬å€¼: {sample_val}, å”¯ä¸€å€¼æ•°é‡: {unique_values})")

                        columns_description = "\n".join(column_info)

                        data_context = f"""
                        åˆå¹¶åçš„ä¸»æ•°æ®è¡¨:
                        {df_info_formatted}
                        
                        ä¸»æ•°æ®è¡¨æ ·æœ¬ï¼ˆå‰{sample_rows}è¡Œï¼‰:
                        {df_sample_formatted}
                        
                        ä¸»æ•°æ®è¡¨åˆ—ä¿¡æ¯:
                        {columns_description}
                        
                        å½“å‰ä¸»æ•°æ®è¡¨æœ‰{len(combined_df)}æ¡è®°å½•ï¼Œæ¥è‡ª{len(st.session_state.uploaded_files_info)}ä¸ªæ–‡ä»¶ã€‚
                        
                        -------- æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶çš„æ•°æ®æ ·æœ¬ --------
                        {all_dfs_context}
                        """
                    except Exception as e:
                        # å¦‚æœä¸»æ•°æ®æ¡†ç»Ÿè®¡å¤±è´¥ï¼Œåªæä¾›æ‰€æœ‰æ–‡ä»¶çš„æ ·æœ¬
                        data_context = f"""
                        æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶çš„æ•°æ®æ ·æœ¬:
                        {all_dfs_context}
                        
                        æ³¨æ„: ç”Ÿæˆä¸»æ•°æ®è¡¨ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}
                        """
                    
                    # å°†æ•°æ®èƒŒæ™¯ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ ä¾›åç»­APIè°ƒç”¨ä½¿ç”¨
                    st.session_state.data_context = data_context
                    
                    st.success(f"æˆåŠŸè¯»å–{len(st.session_state.uploaded_files_info)}ä¸ªæ–‡ä»¶ï¼Œåˆå¹¶åä¸»æ•°æ®è¡¨åŒ…å«{len(combined_df)}æ¡è®°å½•")
                elif len(st.session_state.all_dataframes) > 0:
                    # å³ä½¿ä¸»æ•°æ®æ¡†ä¸ºç©ºï¼Œä½†ä»æœ‰è¯»å–åˆ°æ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥ç»§ç»­
                    st.session_state.original_df = pd.DataFrame()  # åˆ›å»ºç©ºçš„ä¸»æ•°æ®æ¡†
                    st.session_state.processed_df = None
                    st.session_state.processing_msg = ""
                    st.session_state.analysis_result = ""
                    
                    # æ¸…ç©ºä¹‹å‰çš„èŠå¤©è®°å½•
                    st.session_state.chat_messages = []
                    st.session_state.processed_chat_messages = []
                    
                    # æ„å»ºæ–‡ä»¶ä¿¡æ¯æ‘˜è¦
                    files_summary = ""
                    for i, file_info in enumerate(st.session_state.uploaded_files_info):
                        files_summary += f"ğŸ“„ {i+1}. {file_info['filename']}: {file_info['rows']}è¡Œæ•°æ®ï¼Œ{len(file_info['columns'])}åˆ—\n"
                    
                    # æ„å»ºåˆå§‹ç³»ç»Ÿæ¶ˆæ¯
                    initial_message = f"""æ‚¨å¥½ï¼æˆ‘å·²æˆåŠŸè¯»å–æ‚¨ä¸Šä¼ çš„{len(st.session_state.uploaded_files_info)}ä¸ªæ–‡ä»¶ã€‚

å·²å¤„ç†çš„æ–‡ä»¶ï¼š
{files_summary}

ç”±äºæ–‡ä»¶ç»“æ„å·®å¼‚è¾ƒå¤§ï¼Œæœªåˆ›å»ºåˆå¹¶æ•°æ®è¡¨ï¼Œä½†æ‚¨å¯ä»¥è¯¢é—®å…³äºä»»ä½•å·²ä¸Šä¼ æ–‡ä»¶çš„é—®é¢˜ã€‚"""

                    st.session_state.chat_messages.append({
                        "role": "assistant", 
                        "content": initial_message
                    })
                    
                    # æä¾›æ‰€æœ‰æ•°æ®æ¡†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
                    all_dfs_context = ""
                    for i, df_info in enumerate(st.session_state.all_dataframes):
                        filename = df_info["filename"]
                        df = df_info["dataframe"]
                        # æœ€å¤š10è¡Œæ ·æœ¬
                        sample_rows = min(10, len(df))
                        df_sample = format_dataframe(df, sample_rows)
                        all_dfs_context += f"\næ–‡ä»¶ {i+1}: {filename}\n{df_sample}\n\n"
                    
                    data_context = f"""
                    æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶çš„æ•°æ®æ ·æœ¬:
                    {all_dfs_context}
                    """
                    
                    # å°†æ•°æ®èƒŒæ™¯ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ ä¾›åç»­APIè°ƒç”¨ä½¿ç”¨
                    st.session_state.data_context = data_context
                    
                    st.success(f"æˆåŠŸè¯»å–{len(st.session_state.uploaded_files_info)}ä¸ªæ–‡ä»¶ï¼Œä½†ç”±äºç»“æ„å·®å¼‚è¾ƒå¤§ï¼Œæœªåˆ›å»ºåˆå¹¶æ•°æ®è¡¨")
                else:
                    st.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
    if st.session_state.uploaded_files_info:
        with st.expander("æŸ¥çœ‹å·²å¤„ç†æ–‡ä»¶è¯¦æƒ…"):
            for i, file_info in enumerate(st.session_state.uploaded_files_info):
                st.write(f"ğŸ“„ {i+1}. **{file_info['filename']}**")
                st.write(f"   - è¡Œæ•°: {file_info['rows']}")
                st.write(f"   - åˆ—æ•°: {len(file_info['columns'])}")
                st.write(f"   - åˆ—å: {', '.join(file_info['columns'][:5])}{'...' if len(file_info['columns']) > 5 else ''}")
                
    st.markdown('</div>', unsafe_allow_html=True)

# ç¬¬äºŒæ­¥ï¼šæ˜¾ç¤ºåŸå§‹æ•°æ®å’ŒèŠå¤©ç•Œé¢
if st.session_state.original_df is not None:
    with st.container():
        st.markdown('<div class="step-container">', unsafe_allow_html=True)
        st.subheader("ç¬¬äºŒæ­¥ï¼šæŸ¥çœ‹åŸå§‹æ•°æ®")
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰20è¡Œ
        st.dataframe(st.session_state.original_df.head(20), use_container_width=True)
        
        # åˆ›å»ºèŠå¤©æœºå™¨äººç•Œé¢
        st.markdown("### æ•°æ®åŠ©æ‰‹")
        st.markdown("æ‚¨å¯ä»¥å‘æ•°æ®åŠ©æ‰‹è¯¢é—®å…³äºåŸå§‹æ•°æ®çš„é—®é¢˜ï¼ŒåŠ©æ‰‹ä¼šè®°ä½ä¸Šä¸‹æ–‡å¹¶æ”¯æŒå¤šè½®å¯¹è¯ã€‚æ‚¨è¿˜å¯ä»¥è¦æ±‚ç”Ÿæˆè¡¨æ ¼å¹¶ä¸‹è½½ã€‚")
        st.markdown("_æ³¨æ„ï¼šå¯¹è¯å¼€å§‹æ—¶åŠ©æ‰‹åªä¼šç®€å•æ˜¾ç¤ºå·²è¯»å–æ–‡ä»¶çš„ä¿¡æ¯ï¼Œè€Œä¸å±•ç¤ºæ•°æ®æ ·æœ¬ï¼Œä»¥ä¿æŒç•Œé¢ç®€æ´ã€‚_")
        
        # ä½¿ç”¨StreamlitåŸç”ŸèŠå¤©ç»„ä»¶æ˜¾ç¤ºå†å²æ¶ˆæ¯
        for i, message in enumerate(st.session_state.chat_messages):
            with st.chat_message(message["role"]):
                # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
                st.markdown(message["content"])
        
        # ä½¿ç”¨StreamlitåŸç”ŸèŠå¤©è¾“å…¥ç»„ä»¶
        if user_input := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–è¯·æ±‚ç”Ÿæˆè¡¨æ ¼", key="chat_input_field"):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
            st.session_state.chat_messages.append({
                "role": "user", 
                "content": user_input
            })
            
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(user_input)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼ç”Ÿæˆè¯·æ±‚
            is_table_request = False
            table_keywords = ["è¡¨æ ¼", "ç”Ÿæˆè¡¨", "åˆ›å»ºè¡¨", "åˆ¶ä½œè¡¨", "æ±‡æ€»è¡¨", "å¯¼å‡ºè¡¨", "ç»Ÿè®¡è¡¨", "åˆ†æè¡¨", 
                             "è¡¨å•", "ç”µå­è¡¨æ ¼", "excel", "è½¬ä¸ºè¡¨æ ¼", "åšä¸ªè¡¨", "åšä¸€ä¸ªè¡¨", "æ•°æ®è¡¨", "åˆ—è¡¨"]

            # æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦åŒ…å«è¡¨æ ¼ç›¸å…³å…³é”®è¯
            for keyword in table_keywords:
                if keyword in user_input.lower():
                    is_table_request = True
                    break

            # æ›´æ™ºèƒ½çš„åˆ†æï¼šæ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼ç”Ÿæˆæ„å›¾
            if not is_table_request:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ±‡æ€»ã€å¯¼å‡ºã€æ•´ç†ç­‰ä¸è¡¨æ ¼ç›¸å…³çš„åŠ¨ä½œè¯
                action_keywords = ["æ±‡æ€»", "å¯¼å‡º", "æ•´ç†", "å½’çº³", "åˆ†ç»„", "åˆ†ç±»", "ç»Ÿè®¡", "è®¡ç®—æ€»å’Œ", 
                                  "è®¡ç®—å¹³å‡", "æ’åº", "ç­›é€‰", "ç»“æ„åŒ–", "å¯è§†åŒ–"]
                data_keywords = ["æ•°æ®", "ä¿¡æ¯", "è®°å½•", "è´¹ç”¨", "é‡‘é¢", "äººå‘˜", "å®¿èˆ", "æ¥¼å·", "æˆ¿é—´"]
                
                action_match = any(keyword in user_input for keyword in action_keywords)
                data_match = any(keyword in user_input for keyword in data_keywords)
                
                # å¦‚æœåŒæ—¶åŒ¹é…åŠ¨ä½œè¯å’Œæ•°æ®è¯ï¼Œå¾ˆå¯èƒ½æ˜¯è¡¨æ ¼è¯·æ±‚
                if action_match and data_match:
                    is_table_request = True
            
            # æ„å»ºæ¶ˆæ¯å†å²ç”¨äºAPIè¯·æ±‚
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œç†Ÿæ‚‰å®¿èˆè´¹ç”¨æ•°æ®ã€‚è¯·ç”¨ç®€ä½“ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"}
            ]
            
            # æ·»åŠ å†å²æ¶ˆæ¯ï¼Œä½†ç¡®ä¿æ€»æ•°ä¸è¶…è¿‡10æ¡ä»¥æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
            chat_history = []
            for msg in st.session_state.chat_messages[-10:]:
                history_msg = {"role": msg["role"], "content": msg["content"]}
                chat_history.append(history_msg)
            
            # å°†å†å²æ¶ˆæ¯æ·»åŠ åˆ°APIè¯·æ±‚
            messages.extend(chat_history)
            
            # æ·»åŠ æ•°æ®èƒŒæ™¯ä¿¡æ¯åˆ°ç³»ç»Ÿæ¶ˆæ¯
            if hasattr(st.session_state, 'data_context') and st.session_state.data_context:
                messages[0]["content"] += f"\n\n{st.session_state.data_context}"
            else:
                # å¦‚æœæ²¡æœ‰å­˜å‚¨çš„æ•°æ®ä¸Šä¸‹æ–‡ï¼Œåˆ™ç”Ÿæˆä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬
                # æä¾›æ•°æ®èƒŒæ™¯ä¿¡æ¯
                df_info = pd.DataFrame({
                    'ç»Ÿè®¡é‡': st.session_state.original_df.describe().index,
                    **{col: st.session_state.original_df[col].describe() for col in st.session_state.original_df.select_dtypes(include=np.number).columns[:5]}  # é™åˆ¶ä¸ºå‰5ä¸ªæ•°å€¼åˆ—
                })
                df_info_formatted = format_dataframe(df_info)

                # è·å–å®é™…æ•°æ®æ ·æœ¬ï¼Œä¸ä»…ä»…æ˜¯ç»Ÿè®¡æ‘˜è¦
                sample_rows = min(15, len(st.session_state.original_df))  # æœ€å¤š15è¡Œæ ·æœ¬
                df_sample_formatted = format_dataframe(st.session_state.original_df, sample_rows)

                # è·å–åˆ—åè¯¦ç»†åˆ—è¡¨
                column_info = []
                for col in st.session_state.original_df.columns:
                    dtype = str(st.session_state.original_df[col].dtype)
                    unique_values = st.session_state.original_df[col].nunique()
                    sample_val = str(st.session_state.original_df[col].iloc[0])
                    if len(sample_val) > 30:  # å¦‚æœæ ·æœ¬å€¼å¤ªé•¿ï¼Œæˆªæ–­å®ƒ
                        sample_val = sample_val[:30] + "..."
                    column_info.append(f"- {col}: {dtype} (æ ·æœ¬å€¼: {sample_val}, å”¯ä¸€å€¼æ•°é‡: {unique_values})")

                columns_description = "\n".join(column_info)

                data_context = f"""
                æ•°æ®æ‘˜è¦:
                {df_info_formatted}
                
                å®é™…æ•°æ®æ ·æœ¬ï¼ˆå‰{sample_rows}è¡Œï¼‰:
                {df_sample_formatted}
                
                åˆ—ä¿¡æ¯è¯¦ç»†:
                {columns_description}
                
                å½“å‰æœ‰{len(st.session_state.original_df)}æ¡æ•°æ®è®°å½•ã€‚
                """
                
                # å°†æ•°æ®èƒŒæ™¯ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°æœ€å‰é¢
                messages[0]["content"] += f"\n\n{data_context}"
            
            # æ˜¾ç¤ºåŠ©æ‰‹æ­£åœ¨è¾“å…¥çš„çŠ¶æ€
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                message_placeholder.markdown("æ€è€ƒä¸­...")
                
                try:
                    # è·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
                    selected_model = st.session_state.selected_model
                    
                    # å¦‚æœæ˜¯è¡¨æ ¼ç”Ÿæˆè¯·æ±‚ï¼Œä½¿ç”¨è¡¨æ ¼ç”ŸæˆåŠŸèƒ½
                    if is_table_request:
                        message_placeholder.markdown("æ­£åœ¨ç”Ÿæˆè¡¨æ ¼æ•°æ®...")
                        
                        # ä¼ é€’æ‰€æœ‰æ–‡ä»¶æ•°æ®æ¡† - æ–°å¢å†…å®¹
                        # ç”Ÿæˆè¡¨æ ¼JSONæ•°æ®ï¼Œä¼ é€’èŠå¤©å†å²è®°å½•å’Œæ‰€æœ‰è¯»å–çš„æ–‡ä»¶æ•°æ®
                        table_json, msg = processor.generate_table_from_chat(
                            st.session_state.original_df, 
                            user_input,
                            chat_messages=st.session_state.chat_messages,
                            all_dataframes=st.session_state.all_dataframes  # ä¼ é€’æ‰€æœ‰æ•°æ®æ¡†ä¿¡æ¯
                        )
                        
                        if "error" in table_json:
                            content = f"æŠ±æ­‰ï¼Œç”Ÿæˆè¡¨æ ¼æ—¶å‡ºé”™: {table_json['error']}"
                        else:
                            # ç”Ÿæˆè¡¨æ ¼é¢„è§ˆå’Œä¸‹è½½é€‰é¡¹
                            preview_text = f"""### {table_json.get('table_name', 'æ•°æ®è¡¨æ ¼')}

**è¡¨æ ¼æè¿°**ï¼š{table_json.get('summary', 'è¡¨æ ¼æ•°æ®')}

**è¡¨æ ¼é¢„è§ˆ**ï¼š"""

                            # æ˜¾ç¤ºè¡¨æ ¼å¤´éƒ¨é¢„è§ˆ
                            headers = table_json.get("headers", [])
                            data_rows = table_json.get("data", [])

                            # åˆ›å»ºè¡¨æ ¼é¢„è§ˆ
                            if headers and data_rows:
                                # åˆ›å»ºmarkdownè¡¨æ ¼
                                table_md = "| " + " | ".join(headers) + " |\n"
                                table_md += "| " + " | ".join(["---" for _ in headers]) + " |\n"
                                
                                # æ˜¾ç¤ºæ‰€æœ‰æ•°æ®è¡Œ
                                for i in range(len(data_rows)):
                                    # ç¡®ä¿æ‰€æœ‰å•å…ƒæ ¼å†…å®¹ä¸ºå­—ç¬¦ä¸²å¹¶é™åˆ¶é•¿åº¦
                                    row_data = []
                                    for cell in data_rows[i]:
                                        cell_str = str(cell) if cell is not None else ""
                                        # å¦‚æœå•å…ƒæ ¼å†…å®¹å¤ªé•¿ï¼Œæˆªæ–­å®ƒ
                                        if len(cell_str) > 20:
                                            cell_str = cell_str[:17] + "..."
                                        row_data.append(cell_str)
                                    
                                    table_md += "| " + " | ".join(row_data) + " |\n"
                                
                                preview_text += f"\n{table_md}\n\n"
                            else:
                                if headers:
                                    # å¦‚æœæœ‰è¡¨å¤´ä½†æ²¡æœ‰æ•°æ®è¡Œï¼Œæ˜¾ç¤ºç©ºè¡¨æ ¼
                                    table_md = "| " + " | ".join(headers) + " |\n"
                                    table_md += "| " + " | ".join(["---" for _ in headers]) + " |\n"
                                    table_md += "| " + " | ".join(["" for _ in headers]) + " |\n"
                                    preview_text += f"\n{table_md}\n\n*è¡¨æ ¼æš‚æ— æ•°æ®*\n\n"
                                else:
                                    preview_text += "\n\n*è¡¨æ ¼æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®*\n\n"

                            # æ·»åŠ è¡¨æ ¼ç»Ÿè®¡ä¿¡æ¯
                            preview_text += f"""**è¡¨æ ¼ç»Ÿè®¡ä¿¡æ¯**ï¼š
                            - æ€»è¡Œæ•°ï¼š{len(data_rows)}
                            - æ€»åˆ—æ•°ï¼š{len(headers)}
                            - ç”Ÿæˆæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}

                            æ‚¨å¯ä»¥åœ¨ä¸‹æ–¹ä¸‹è½½å®Œæ•´è¡¨æ ¼ã€‚"""

                            # è®¾ç½®ä¼šè¯çŠ¶æ€ä¿å­˜è¡¨æ ¼æ•°æ®ä¾›ä¸‹è½½
                            st.session_state.table_json = table_json

                            content = preview_text
                        
                        # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
                        message_placeholder.markdown(content)
                        
                        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°èŠå¤©å†å²
                        st.session_state.chat_messages.append({
                            "role": "assistant", 
                            "content": content
                        })
                    else:
                        # æ™®é€šå¯¹è¯è¯·æ±‚ï¼Œå¤„ç†æµå¼å’Œéæµå¼å¯¹è¯
                        try:
                            # æ·»åŠ æ‰€æœ‰æ–‡ä»¶çš„ä¸Šä¸‹æ–‡ä¿¡æ¯åˆ°ç³»ç»Ÿæ¶ˆæ¯ - ä¿®æ”¹å†…å®¹
                            if hasattr(st.session_state, 'data_context') and st.session_state.data_context:
                                # ç¡®è®¤messagesç¬¬ä¸€æ¡æ˜¯ç³»ç»Ÿæ¶ˆæ¯
                                if messages[0]["role"] == "system":
                                    # æ·»åŠ æ•°æ®ä¸Šä¸‹æ–‡
                                    messages[0]["content"] += f"\n\n{st.session_state.data_context}"
                                    
                                    # æ·»åŠ å…³äºæŸ¥è¯¢å¤šä¸ªæ–‡ä»¶çš„é¢å¤–æç¤º
                                    if len(st.session_state.all_dataframes) > 1:
                                        messages[0]["content"] += "\n\nè¯·ç‰¹åˆ«æ³¨æ„ï¼šç”¨æˆ·å¯èƒ½åœ¨è¯¢é—®ä»»ä½•ä¸€ä¸ªå·²ä¸Šä¼ çš„æ–‡ä»¶ï¼Œè¯·æ ¹æ®é—®é¢˜å†…å®¹ç¡®å®šç”¨æˆ·å…³æ³¨çš„æ˜¯å“ªä¸ªæ–‡ä»¶çš„æ•°æ®ï¼Œæˆ–è€…ç»¼åˆåˆ†ææ‰€æœ‰æ–‡ä»¶çš„æ•°æ®ã€‚"
                                
                            # ä½¿ç”¨deepseek-chatæ¨¡å‹
                            model = "deepseek-chat"
                            
                            content, _ = processor.api.stream_chat_completion(messages, model)
                            
                            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
                            message_placeholder.markdown(content)
                            
                            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°èŠå¤©å†å²
                            st.session_state.chat_messages.append({
                                "role": "assistant", 
                                "content": content
                            })
                        except Exception as e:
                            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
                            content = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
                            message_placeholder.markdown(content)
                            st.session_state.chat_messages.append({
                                "role": "assistant", 
                                "content": content
                            })
                
                except Exception as e:
                    # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                    error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
                    message_placeholder.markdown(error_msg)
                    st.session_state.chat_messages.append({
                        "role": "assistant", 
                        "content": error_msg
                    })
        
        # æä¾›è¡¨æ ¼ä¸‹è½½åŠŸèƒ½
        if 'table_json' in st.session_state and st.session_state.table_json:
            st.markdown("### ä¸‹è½½ç”Ÿæˆçš„è¡¨æ ¼")
            
            try:
                # ä»JSONåˆ›å»ºExcelæ–‡ä»¶
                try:
                    excel_data, filename = processor.create_excel_from_json(st.session_state.table_json)
                    
                    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åç¡®å®šæ–‡ä»¶ç±»å‹
                    is_excel = filename.lower().endswith('.xlsx')
                    mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" if is_excel else "text/csv"
                    
                    # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
                    st.download_button(
                        label=f"ä¸‹è½½{st.session_state.table_json.get('table_name', 'æ•°æ®è¡¨æ ¼')}",
                        data=excel_data,
                        file_name=filename,
                        mime=mime_type
                    )
                    
                    if not is_excel:
                        st.info("æ³¨æ„ï¼šç”±äºç³»ç»Ÿé™åˆ¶ï¼Œè¡¨æ ¼ä»¥CSVæ ¼å¼ä¸‹è½½ã€‚è¯·å®‰è£…xlsxwriteråº“ä»¥å¯ç”¨Excelä¸‹è½½ã€‚")
                except Exception as excel_error:
                    st.error(f"Excelç”Ÿæˆå¤±è´¥: {str(excel_error)}ï¼Œå°†æä¾›CSVä¸‹è½½é€‰é¡¹")
                    
                # åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„CSVå¤‡é€‰æ–¹æ¡ˆ
                if "headers" in st.session_state.table_json and "data" in st.session_state.table_json:
                    # ç¡®ä¿dataæ˜¯æœ‰æ•ˆçš„äºŒç»´æ•°ç»„
                    data = st.session_state.table_json["data"]
                    headers = st.session_state.table_json["headers"]
                    
                    # å¤„ç†dataä¸ºç©ºçš„æƒ…å†µ
                    if not data or len(data) == 0:
                        # åˆ›å»ºä¸€ä¸ªåªæœ‰è¡¨å¤´çš„ç©ºDataFrame
                        df = pd.DataFrame(columns=headers)
                    else:
                        # æ£€æŸ¥æ¯è¡Œæ˜¯å¦æœ‰è¶³å¤Ÿçš„åˆ—
                        clean_data = []
                        for row in data:
                            # å¦‚æœè¡Œæ•°æ®æ˜¯Noneï¼Œåˆ›å»ºç©ºè¡Œ
                            if row is None:
                                clean_data.append([None] * len(headers))
                            # å¤„ç†ç©ºåˆ—è¡¨çš„æƒ…å†µ
                            elif len(row) == 0:
                                clean_data.append([None] * len(headers))
                            # ç¡®ä¿è¡Œé•¿åº¦ä¸è¡¨å¤´åŒ¹é…
                            elif len(row) < len(headers):
                                # å¡«å……ç¼ºå°‘çš„å•å…ƒæ ¼ä¸ºNone
                                padded_row = row + [None] * (len(headers) - len(row))
                                clean_data.append(padded_row)
                            else:
                                clean_data.append(row)
                                
                        df = pd.DataFrame(clean_data, columns=headers)
                        
                    # å¤„ç†æ•°æ®ä¸­çš„Noneå€¼
                    df = df.fillna("")
                    
                    csv_data = df.to_csv(index=False).encode('utf-8-sig')
                    table_name = st.session_state.table_json.get('table_name', 'æ•°æ®è¡¨æ ¼')
                    timestamp = int(time.time())
                    
                    st.download_button(
                        label=f"ä¸‹è½½{table_name} (CSVæ ¼å¼)",
                        data=csv_data,
                        file_name=f"{table_name}_{timestamp}.csv",
                        mime="text/csv"
                    )
                
                # æ·»åŠ æŸ¥çœ‹è¯¦æƒ…çš„å±•å¼€éƒ¨åˆ†
                with st.expander("æŸ¥çœ‹è¡¨æ ¼è¯¦ç»†æ•°æ®"):
                    st.json(st.session_state.table_json)
                    
                    # å¦‚æœæœ‰ç›¸å½“æ•°é‡çš„æ•°æ®ï¼Œè¿˜å¯ä»¥æ˜¾ç¤ºä¸ºDataFrame
                    if "headers" in st.session_state.table_json and "data" in st.session_state.table_json:
                        # ç¡®ä¿dataæ˜¯æœ‰æ•ˆçš„äºŒç»´æ•°ç»„
                        data = st.session_state.table_json["data"]
                        headers = st.session_state.table_json["headers"]
                        
                        try:
                            # å¤„ç†dataä¸ºç©ºçš„æƒ…å†µ
                            if not data or len(data) == 0:
                                # åˆ›å»ºä¸€ä¸ªåªæœ‰è¡¨å¤´çš„ç©ºDataFrame
                                df = pd.DataFrame(columns=headers)
                                st.info("è¡¨æ ¼æ•°æ®ä¸ºç©º")
                            else:
                                # æ£€æŸ¥æ¯è¡Œæ˜¯å¦æœ‰è¶³å¤Ÿçš„åˆ—
                                clean_data = []
                                for row in data:
                                    # å¦‚æœè¡Œæ•°æ®æ˜¯Noneï¼Œåˆ›å»ºç©ºè¡Œ
                                    if row is None:
                                        clean_data.append([None] * len(headers))
                                    # å¤„ç†ç©ºåˆ—è¡¨çš„æƒ…å†µ
                                    elif len(row) == 0:
                                        clean_data.append([None] * len(headers))
                                    # ç¡®ä¿è¡Œé•¿åº¦ä¸è¡¨å¤´åŒ¹é…
                                    elif len(row) < len(headers):
                                        # å¡«å……ç¼ºå°‘çš„å•å…ƒæ ¼ä¸ºNone
                                        padded_row = row + [None] * (len(headers) - len(row))
                                        clean_data.append(padded_row)
                                    else:
                                        clean_data.append(row)
                                        
                                df = pd.DataFrame(clean_data, columns=headers)
                            
                            # å¤„ç†æ•°æ®ä¸­çš„Noneå€¼
                            df = df.fillna("")
                            
                            st.dataframe(df, use_container_width=True)
                        except Exception as df_error:
                            st.error(f"æ˜¾ç¤ºè¡¨æ ¼æ•°æ®æ—¶å‡ºé”™: {str(df_error)}")
                            st.write("åŸå§‹æ•°æ®:")
                            st.write(st.session_state.table_json)
            except Exception as e:
                st.error(f"å‡†å¤‡è¡¨æ ¼ä¸‹è½½æ—¶å‡ºé”™: {str(e)}")
                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ - ç›´æ¥æ˜¾ç¤ºæ•°æ®
                st.write("è¡¨æ ¼æ•°æ®ï¼š")
                st.write(st.session_state.table_json)
        
        st.markdown('</div>', unsafe_allow_html=True)

# ç¬¬ä¸‰æ­¥ï¼šæ˜¾ç¤ºå¤„ç†ç»“æœ
if st.session_state.processed_df is not None:
    with st.container():
        st.markdown('<div class="step-container">', unsafe_allow_html=True)
        st.subheader("ç¬¬ä¸‰æ­¥ï¼šæŸ¥çœ‹å¤„ç†ç»“æœ")
        
        # æ˜¾ç¤ºå¤„ç†æ¶ˆæ¯
        if st.session_state.processing_msg:
            st.markdown(f'<div class="info-box">{st.session_state.processing_msg}</div>', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®
        st.dataframe(st.session_state.processed_df, use_container_width=True)
        
        # åˆ›å»ºå¤„ç†ç»“æœèŠå¤©æœºå™¨äººç•Œé¢
        st.markdown("### ç»“æœåˆ†æåŠ©æ‰‹")
        st.markdown("æ‚¨å¯ä»¥å‘ç»“æœåˆ†æåŠ©æ‰‹è¯¢é—®å…³äºå¤„ç†ç»“æœçš„é—®é¢˜ï¼ŒåŠ©æ‰‹ä¼šè®°ä½ä¸Šä¸‹æ–‡å¹¶æ”¯æŒå¤šè½®å¯¹è¯ã€‚")
        
        # ä½¿ç”¨StreamlitåŸç”ŸèŠå¤©ç»„ä»¶æ˜¾ç¤ºå†å²æ¶ˆæ¯
        for i, message in enumerate(st.session_state.processed_chat_messages):
            with st.chat_message(message["role"]):
                # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
                st.markdown(message["content"])
        
        # ä½¿ç”¨StreamlitåŸç”ŸèŠå¤©è¾“å…¥ç»„ä»¶
        if processed_input := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜", key="processed_chat_input_field"):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
            st.session_state.processed_chat_messages.append({
                "role": "user", 
                "content": processed_input
            })
            
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(processed_input)
            
            # æ„å»ºæ¶ˆæ¯å†å²ç”¨äºAPIè¯·æ±‚
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œç†Ÿæ‚‰å®¿èˆè´¹ç”¨è®¡ç®—ç»“æœæ•°æ®ã€‚è¯·ç”¨ç®€ä½“ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"}
            ]
            
            # æ·»åŠ å†å²æ¶ˆæ¯ï¼Œä½†ç¡®ä¿æ€»æ•°ä¸è¶…è¿‡10æ¡ä»¥æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
            chat_history = []
            for msg in st.session_state.processed_chat_messages[-10:]:
                history_msg = {"role": msg["role"], "content": msg["content"]}
                chat_history.append(history_msg)
            
            # å°†å†å²æ¶ˆæ¯æ·»åŠ åˆ°APIè¯·æ±‚
            messages.extend(chat_history)
            
            # æä¾›æ•°æ®èƒŒæ™¯ä¿¡æ¯
            df_info = st.session_state.processed_df.describe().to_string()
            # è·å–å®é™…æ•°æ®æ ·æœ¬ï¼Œä¸ä»…ä»…æ˜¯ç»Ÿè®¡æ‘˜è¦
            sample_rows = min(15, len(st.session_state.processed_df))  # æœ€å¤š15è¡Œæ ·æœ¬
            df_sample = st.session_state.processed_df.head(sample_rows).to_string()
            
            # è·å–åˆ—åè¯¦ç»†åˆ—è¡¨
            column_info = []
            for col in st.session_state.processed_df.columns:
                unique_values = st.session_state.processed_df[col].nunique()
                sample_val = str(st.session_state.processed_df[col].iloc[0])
                if len(sample_val) > 30:  # å¦‚æœæ ·æœ¬å€¼å¤ªé•¿ï¼Œæˆªæ–­å®ƒ
                    sample_val = sample_val[:30] + "..."
                column_info.append(f"- {col}: {st.session_state.processed_df[col].dtype} (æ ·æœ¬å€¼: {sample_val}, å”¯ä¸€å€¼æ•°é‡: {unique_values})")
            
            columns_description = "\n".join(column_info)
            
            data_context = f"""
            æ•°æ®æ‘˜è¦:
            {df_info}
            
            å®é™…æ•°æ®æ ·æœ¬ï¼ˆå‰{sample_rows}è¡Œï¼‰:
            {df_sample}
            
            åˆ—ä¿¡æ¯è¯¦ç»†:
            {columns_description}
            
            å½“å‰æœ‰{len(st.session_state.processed_df)}æ¡æ•°æ®è®°å½•ã€‚
            è®¡ç®—è§„åˆ™è¯´æ˜:
            - ä¸ªäººæ°´ç”µè´¹ = å…¥ä½å¤©æ•° Ã· åˆè®¡å¤©æ•° Ã— å®¿èˆæ°´ç”µè´¹
            - ä¸ªäººç§Ÿé‡‘ï¼ˆè‡ªè´¹äººå‘˜ï¼‰= ç§Ÿé‡‘ Ã· åºŠä½æ•° Ã— å…¥ä½å¤©æ•° Ã· åˆè®¡å¤©æ•°
            - åˆè®¡ = ä¸ªäººæ°´ç”µè´¹ + ä¸ªäººç§Ÿé‡‘
            """
            
            # å°†æ•°æ®èƒŒæ™¯ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°æœ€å‰é¢
            messages[0]["content"] += f"\n\n{data_context}"
            
            # æ˜¾ç¤ºåŠ©æ‰‹æ­£åœ¨è¾“å…¥çš„çŠ¶æ€
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                message_placeholder.markdown("æ€è€ƒä¸­...")
                
                try:
                    # ä½¿ç”¨deepseek-chatæ¨¡å‹
                    content, _ = processor.stream_chat_completion(messages, "deepseek-chat")
                    
                    # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
                    message_placeholder.markdown(content)
                    
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°èŠå¤©å†å²
                    st.session_state.processed_chat_messages.append({
                        "role": "assistant", 
                        "content": content
                    })
                    
                except Exception as e:
                    # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                    error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
                    message_placeholder.markdown(error_msg)
                    st.session_state.processed_chat_messages.append({
                        "role": "assistant", 
                        "content": error_msg
                    })
        
        # æä¾›ä¸‹è½½åŠŸèƒ½
        st.markdown("### ä¸‹è½½ç”Ÿæˆçš„è¡¨æ ¼")
        col1, col2 = st.columns([1, 1])
        
        with col1:
            csv = st.session_state.processed_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ä¸‹è½½CSVç»“æœ",
                data=csv,
                file_name="å®¿èˆè´¹ç”¨è®¡ç®—ç»“æœ.csv",
                mime="text/csv"
            )
        
        with col2:
            try:
                # åˆ›å»ºè¾“å‡ºç¼“å†²åŒº
                buffer = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx')
                buffer.close()
                
                # å†™å…¥Excelæ–‡ä»¶ï¼Œå°è¯•å¤šç§å¼•æ“
                try:
                    # é¦–å…ˆå°è¯•xlsxwriterå¼•æ“
                    with pd.ExcelWriter(buffer.name, engine='xlsxwriter') as writer:
                        st.session_state.processed_df.to_excel(writer, index=False, sheet_name='è®¡ç®—ç»“æœ')
                except ImportError:
                    try:
                        # ç„¶åå°è¯•openpyxlå¼•æ“
                        with pd.ExcelWriter(buffer.name, engine='openpyxl') as writer:
                            st.session_state.processed_df.to_excel(writer, index=False, sheet_name='è®¡ç®—ç»“æœ')
                    except ImportError:
                        # æœ€åä½¿ç”¨é»˜è®¤å¼•æ“
                        st.session_state.processed_df.to_excel(buffer.name, index=False, sheet_name='è®¡ç®—ç»“æœ')
                
                # è¯»å–Excelæ–‡ä»¶å†…å®¹
                with open(buffer.name, 'rb') as f:
                    excel_data = f.read()
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(buffer.name)
                except:
                    pass  # å¿½ç•¥åˆ é™¤é”™è¯¯
                
                # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ä¸‹è½½Excelç»“æœ",
                    data=excel_data,
                    file_name="å®¿èˆè´¹ç”¨è®¡ç®—ç»“æœ.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            except Exception as e:
                # å¦‚æœExcelç”Ÿæˆå¤±è´¥ï¼Œæä¾›CSVä¸‹è½½é€‰é¡¹
                st.error(f"Excelç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œå°†æä¾›CSVä¸‹è½½é€‰é¡¹")
                csv = st.session_state.processed_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="ä¸‹è½½CSVç»“æœ (Excelç”Ÿæˆå¤±è´¥)",
                    data=csv,
                    file_name="å®¿èˆè´¹ç”¨è®¡ç®—ç»“æœ.csv",
                    mime="text/csv"
                )
        
        # æ˜¾ç¤ºè‡ªè´¹äººå‘˜è´¹ç”¨æ±‡æ€»
        if 'å…¥ä½æ€§è´¨' in st.session_state.processed_df.columns:
            try:
                # æŸ¥æ‰¾è‡ªè´¹äººå‘˜
                self_paying_rows = st.session_state.processed_df['å…¥ä½æ€§è´¨'].astype(str).str.contains('è‡ªè´¹')
                
                if self_paying_rows.any():
                    st.markdown("### è‡ªè´¹äººå‘˜è´¹ç”¨æ±‡æ€»")
                    
                    # ç­›é€‰è‡ªè´¹äººå‘˜æ•°æ®
                    self_paying_df = st.session_state.processed_df[self_paying_rows].copy()
                    
                    # è®¡ç®—æ±‡æ€»ä¿¡æ¯
                    total_people = len(self_paying_df)
                    total_utility = self_paying_df['ä¸ªäººæ°´ç”µè´¹'].sum()
                    total_rent = self_paying_df['ä¸ªäººç§Ÿé‡‘'].sum()
                    total_amount = self_paying_df['åˆè®¡'].sum()
                    
                    # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                    st.markdown(f'<div class="success-box">'
                                f'<strong>è‡ªè´¹äººå‘˜æ€»æ•°:</strong> {total_people} äºº<br>'
                                f'<strong>æ°´ç”µè´¹æ€»è®¡:</strong> {total_utility:.2f} å…ƒ<br>'
                                f'<strong>ç§Ÿé‡‘æ€»è®¡:</strong> {total_rent:.2f} å…ƒ<br>'
                                f'<strong>è´¹ç”¨æ€»è®¡:</strong> {total_amount:.2f} å…ƒ'
                                f'</div>', unsafe_allow_html=True)
            except Exception as e:
                st.warning(f"è®¡ç®—è‡ªè´¹äººå‘˜æ±‡æ€»æ—¶å‡ºé”™: {str(e)}")
        
        st.markdown('</div>', unsafe_allow_html=True)

# ç¬¬å››æ­¥ï¼šæ•°æ®åˆ†æ
if st.session_state.analysis_result:
    with st.container():
        st.markdown('<div class="step-container">', unsafe_allow_html=True)
        st.subheader("ç¬¬å››æ­¥ï¼šæ•°æ®åˆ†æ")
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        st.markdown(st.session_state.analysis_result)
        st.markdown('</div>', unsafe_allow_html=True)

# é¡µè„šç‰ˆæƒä¿¡æ¯
st.markdown("---")
st.markdown("Â© 2025 åŠå²›æ™ºå®¿ç³»ç»Ÿ v1.0", help="å®¿èˆè´¹ç”¨è®¡ç®—å’Œåˆ†æå·¥å…·")

# ç”¨æˆ·æŒ‡å—
with st.sidebar:
    st.header("ä½¿ç”¨æŒ‡å—")
    
    # æ‰§è¡Œç¯å¢ƒå’Œä¾èµ–æ£€æŸ¥
    env_ok = check_env()
    deps_ok = check_dependencies()
    
    if not env_ok or not deps_ok:
        st.error("âš ï¸ ç¯å¢ƒæ£€æŸ¥å‘ç°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æç¤ºã€‚")
    
    # æ·»åŠ æ¨¡å‹åˆ—è¡¨ç¤ºä¾‹é€‰é¡¹
    if st.checkbox("æŸ¥çœ‹DeepSeekæ¨¡å‹åˆ—è¡¨ç¤ºä¾‹"):
        demo_list_models()
    
    st.markdown("---")
    
    st.markdown("""
    ### å·¥å…·è¯´æ˜
    åŠå²›æ™ºå®¿ç³»ç»Ÿé€šè¿‡æ™ºèƒ½å¯¹è¯æ–¹å¼å¤„ç†å®¿èˆæ•°æ®ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬:
    - æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆæœ€å¤š5ä¸ªExcelæ–‡ä»¶ï¼‰
    - æ™ºèƒ½å¤„ç†ä¸åŒç»“æ„çš„æ•°æ®æ–‡ä»¶
    - é€šè¿‡å¯¹è¯åˆ†æä»»æ„å·²ä¸Šä¼ çš„æ–‡ä»¶
    - ç”Ÿæˆè‡ªå®šä¹‰è¡¨æ ¼å¹¶å¯¼å‡º
    - æ”¯æŒè·¨æ–‡ä»¶æ•°æ®åˆ†æå’Œæ±‡æ€»
    
    ### ä½¿ç”¨æ­¥éª¤
    1. ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªå®¿èˆæ•°æ®Excelæ–‡ä»¶
    2. æŸ¥çœ‹åŸå§‹æ•°æ®å’Œæ–‡ä»¶è¯¦æƒ…
    3. ä¸æ•°æ®åŠ©æ‰‹å¯¹è¯è¯¢é—®ä»»æ„æ–‡ä»¶çš„ä¿¡æ¯
    4. è¯·æ±‚ç”Ÿæˆè¡¨æ ¼ï¼Œæ”¯æŒæ‰€æœ‰å·²ä¸Šä¼ æ–‡ä»¶çš„æ•°æ®
    5. ä¸‹è½½ç”Ÿæˆçš„Excelè¡¨æ ¼
    
    ### å¤šæ–‡ä»¶å¤„ç†ç‰¹æ€§
    - è‡ªåŠ¨è¯†åˆ«å¹¶åˆå¹¶ç›¸åŒç»“æ„çš„æ–‡ä»¶
    - æ”¯æŒå®Œå…¨ä¸åŒç»“æ„çš„å¤šä¸ªæ–‡ä»¶å¹¶è¡Œåˆ†æ
    - å¯ä»¥é’ˆå¯¹ç‰¹å®šæ–‡ä»¶æˆ–æ‰€æœ‰æ–‡ä»¶æé—®
    - è·¨æ–‡ä»¶æ•°æ®æ¯”è¾ƒå’Œæ•´åˆ
    
    ### è¡¨æ ¼ç”Ÿæˆæç¤ºç¤ºä¾‹
    - "è¯·ç”Ÿæˆä¸€ä¸ªå®¿èˆæ°´ç”µè´¹æ±‡æ€»è¡¨"
    - "åˆ†æå¹¶å¯¹æ¯”æ‰€æœ‰æ–‡ä»¶ä¸­çš„è´¹ç”¨æ•°æ®"
    - "æ ¹æ®ç¬¬ä¸€ä¸ªæ–‡ä»¶åˆ›å»ºç”¨æˆ·åå•ï¼Œæ ¹æ®ç¬¬äºŒä¸ªæ–‡ä»¶æ·»åŠ è´¹ç”¨ä¿¡æ¯"
    - "ç»Ÿè®¡ä¸åŒå®¿èˆæ¥¼çš„äººå‘˜å’Œè´¹ç”¨åˆ†å¸ƒæƒ…å†µ"
    """)
    
    st.markdown("Â© 2025 åŠå²›æ™ºå®¿ç³»ç»Ÿ v1.0") 